# PlacementAssignment

Spark Assignment :

1.Created custom schema 2.read parquet file using spark.read.parquet() 3. converted parquet to csv : df1.repartition(1).write.format('com.databricks.spark.csv').save("consumerinternet.csv",header = 'true') 4.read csv using spark.read.csv() 5.merged two files into one : mergeddf = df1.union(df2) mergeddf.show(truncate=False) 6.then solved Questions

Java Assignment:
1.Installed HsqlDb in local machine 2.created java project in eclipse 3.write code for JDBCDriver connection with HsqlDb 4.Created dummy table Hsqldb and checked connection . 5.Created schema and created table named startup 6.then perform Questions 7.built jar for the project
